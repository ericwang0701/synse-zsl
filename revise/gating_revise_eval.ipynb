{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import os.path as osp\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision.models as models\n",
    "from resnext_specialist import VA\n",
    "from data_cnn60 import NTUDataLoaders, AverageMeter, make_dir, get_cases, get_num_classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from ReViSE import VisAE, AttAE, contractive_loss, MMDLoss, sup_bin_pred_loss, multi_class_hinge_loss, triplet_loss\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='View adaptive')\n",
    "# parser.add_argument('--ss', type=int, help=\"No of unseen classes\")\n",
    "# parser.add_argument('--st', type=str, help=\"Type of split\")\n",
    "# parser.add_argument('--dataset', type=str, help=\"dataset path\")\n",
    "# parser.add_argument('--wdir', type=str, help=\"directory to save weights path\")\n",
    "# parser.add_argument('--le', type=str, help=\"language embedding model\")\n",
    "# parser.add_argument('--ve', type=str, help=\"visual embedding model\")\n",
    "# parser.add_argument('--phase', type=str, help=\"train or val\")\n",
    "# parser.add_argument('--gpu', type=str, help=\"gpu device number\")\n",
    "# parser.add_argument('--ntu', type=int, help=\"no of classes\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "gpu = '0'\n",
    "ss = 10\n",
    "st = 'r'\n",
    "dataset_path = 'ntu_results/shift_10_r'\n",
    "# wdir = args.wdir\n",
    "le = 'bert'\n",
    "ve = 'shift'\n",
    "phase = 'train'\n",
    "num_classes = 120\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "\n",
    "seed = 5\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "zvisae_checkpoint = '/ssd_scratch/cvit/pranay.gupta/language_modelling/revise_shift_10_r/bert/main_gvisae_best.pth.tar'\n",
    "zattae_checkpoint = '/ssd_scratch/cvit/pranay.gupta/language_modelling/revise_shift_10_r/bert/main_gattae_best.pth.tar'\n",
    "criterion2 = nn.MSELoss().to(device)\n",
    "att_input_size = 1024\n",
    "att_intermediate_size = 512\n",
    "att_hidden_size = 100\n",
    "attae = VisAE(att_input_size, att_intermediate_size, att_hidden_size).to(device)\n",
    "attae.load_state_dict(torch.load(zattae_checkpoint)['revise_state_dict'], strict=False)\n",
    "attae_optimizer = optim.Adam(attae.parameters(),lr=1e-4, weight_decay = 0.001)\n",
    "attae_scheduler = ReduceLROnPlateau(attae_optimizer, mode='max', factor=0.1, patience=15, cooldown=3, verbose=True)\n",
    "\n",
    "vis_input_size = 256\n",
    "vis_intermediate_size = 512\n",
    "vis_hidden_size = 100\n",
    "visae = AttAE(vis_input_size, vis_hidden_size).to(device)\n",
    "visae.load_state_dict(torch.load(zvisae_checkpoint)['revise_state_dict'], strict=False)\n",
    "visae_optimizer = optim.Adam(visae.parameters(), lr=1e-4)\n",
    "visae_scheduler = ReduceLROnPlateau(visae_optimizer, mode='max', factor=0.1, patience=15, cooldown=3, verbose=True)\n",
    "print(\"Loaded Revise Model\")\n",
    "\n",
    "ntu_loaders = NTUDataLoaders(dataset_path, 'max', 1)\n",
    "train_loader = ntu_loaders.get_train_loader(1024, 8)\n",
    "zsl_loader = ntu_loaders.get_val_loader(1024, 8)\n",
    "val_loader = ntu_loaders.get_test_loader(1024, 8)\n",
    "zsl_out_loader = ntu_loaders.get_val_out_loader(1024, 8)\n",
    "val_out_loader = ntu_loaders.get_test_out_loader(1024, 8)\n",
    "train_size = ntu_loaders.get_train_size()\n",
    "zsl_size = ntu_loaders.get_val_size()\n",
    "val_size = ntu_loaders.get_test_size()\n",
    "print('Train on %d samples, validate on %d samples' % (train_size, zsl_size))\n",
    "\n",
    "if phase == 'val':\n",
    "    gzsl_inds = np.load('./label_splits/'+st+'s'+str(num_classes - ss)+'.npy')\n",
    "    unseen_inds = np.load('./label_splits/'+st+'v'+str(ss)+'_0.npy')\n",
    "    seen_inds = np.load('./label_splits/'+st+'s'+str(num_classes - ss - ss)+'_0.npy')\n",
    "else:\n",
    "    gzsl_inds = np.arange(num_classes)\n",
    "    unseen_inds = np.load('./label_splits/'+st+'u'+str(ss)+'.npy')\n",
    "    seen_inds = np.load('./label_splits/'+st+'s'+str(num_classes - ss)+'.npy')\n",
    "\n",
    "labels = np.load('labels.npy')\n",
    "unseen_labels = labels[unseen_inds]\n",
    "seen_labels = labels[seen_inds]\n",
    "\n",
    "s2v_labels = torch.from_numpy(np.load(le + '_labels.npy')[:num_classes,:]).view([num_classes, att_input_size])\n",
    "s2v_labels = s2v_labels/torch.norm(s2v_labels, dim = 1).view([num_classes, 1]).repeat([1, att_input_size])\n",
    "\n",
    "unseen_s2v_labels = s2v_labels[unseen_inds, :]\n",
    "seen_s2v_labels = s2v_labels[seen_inds, :]\n",
    "\n",
    "\n",
    "def accuracy(class_embedding, vis_trans_out, target, inds):\n",
    "    inds = torch.from_numpy(inds).to(device)\n",
    "    temp_vis = vis_trans_out.unsqueeze(1).expand(vis_trans_out.shape[0], class_embedding.shape[0], vis_trans_out.shape[1])\n",
    "    temp_cemb = class_embedding.unsqueeze(0).expand(vis_trans_out.shape[0], class_embedding.shape[0], vis_trans_out.shape[1])\n",
    "    preds = torch.argmax(torch.sum(temp_vis*temp_cemb, axis=2), -1)\n",
    "    acc = torch.sum(inds[preds] == target).item()/(preds.shape[0])\n",
    "    # print(torch.sum(inds[preds] == target).item())\n",
    "    return acc, torch.sum(temp_vis*temp_cemb, axis=2)\n",
    "\n",
    "def ce_accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "    return correct.mul_(100.0 / batch_size)\n",
    "\n",
    "def get_text_data(target, s2v_labels):\n",
    "    return s2v_labels[target].view(target.shape[0], 1024)\n",
    "\n",
    "\n",
    "def get_w2v_data(target_nouns, w2v_model, nouns):\n",
    "    \n",
    "    srt_inp = torch.zeros([target_nouns.shape[0], 1, target_nouns.shape[1]]).float()\n",
    "    noun_inp = target_nouns.view(target_nouns.shape[0], 1, target_nouns.shape[1]).float()\n",
    "#     verb_inp = torch.view(target_nouns.shape[0], 1, target_nouns.shape[1])\n",
    "    inp = torch.cat([srt_inp, noun_inp], 1)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "    return correct.mul_(100.0 / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zsl_validate(val_loader, visae, attae, epoch):\n",
    "    with torch.no_grad():\n",
    "        losses = AverageMeter()\n",
    "        acces = AverageMeter()\n",
    "        ce_loss_vals = []\n",
    "        ce_acc_vals = []\n",
    "        # trunk.eval()\n",
    "        visae.eval()\n",
    "        attae.eval()\n",
    "        scores = []\n",
    "        class_embeddings = attae(unseen_s2v_labels.to(device).float())[2]\n",
    "        # unseen_class_embeddings = unseen_class_embeddings/torch.norm(unseen_class_embeddings, dim=1).view([unseen_class_embeddings.size(0), 1]).repeat([1, unseen_class_embeddings.shape[1]])\n",
    "        for i, (emb, target) in enumerate(val_loader):\n",
    "            emb = emb.to(device)\n",
    "            # maxmin = maxmin.to(device)\n",
    "            # vis_emb, output = trunk(emb, maxmin)\n",
    "            # vis_emb = emb/torch.norm(emb, dim = 1).view([emb.size(0), 1]).repeat([1, emb.shape[1]])\n",
    "            vis_emb = torch.log(1 + emb)\n",
    "        \n",
    "            vis_hidden, vis_out, vis_trans_out = visae(vis_emb)\n",
    "            vis_recons_loss = criterion2(vis_out, vis_emb)\n",
    "            \n",
    "            att_emb = get_text_data(target, s2v_labels.float()).to(device)\n",
    "            att_hidden, att_out, att_trans_out = attae(att_emb)\n",
    "            att_recons_loss = criterion2(att_out, att_emb)\n",
    "            \n",
    "            # mmd loss\n",
    "            loss_mmd = MMDLoss(vis_hidden, att_hidden).to(device)\n",
    "            \n",
    "            \n",
    "            # supervised binary prediction loss\n",
    "            pred_loss = multi_class_hinge_loss(vis_trans_out, att_trans_out, target, class_embeddings)\n",
    "            # pred_loss = sup_bin_pred_loss(vis_trans_out, att_trans_out)\n",
    "            # vis_trans_out = vis_trans_out/torch.norm(vis_trans_out, dim = 0).view([1, vis_trans_out.size(1)]).repeat([vis_trans_out.shape[0], 1])\n",
    "            # att_trans_out = att_trans_out/torch.norm(att_trans_out, dim = 0).view([1, att_trans_out.size(1)]).repeat([att_trans_out.shape[0], 1])\n",
    "            # vis_trans_out = vis_trans_out/torch.norm(vis_trans_out, dim = 1).view([vis_trans_out.size(0), 1]).repeat([1, vis_trans_out.shape[1]])\n",
    "            # att_trans_out = att_trans_out/torch.norm(att_trans_out, dim = 1).view([att_trans_out.size(0), 1]).repeat([1, att_trans_out.shape[1]])\n",
    "            # sup_bin_pred_loss = (-1/vis_trans_out.shape[0]) * torch.sum(vis_trans_out*att_trans_out)\n",
    "\n",
    "            loss = pred_loss + vis_recons_loss + att_recons_loss + loss_mmd\n",
    "            acc, score = accuracy(class_embeddings, vis_trans_out, target.to(device), unseen_inds)\n",
    "            losses.update(loss.item(), emb.size(0))\n",
    "            acces.update(acc, emb.size(0))\n",
    "            scores.append(score)\n",
    "            ce_loss_vals.append(loss.cpu().detach().numpy())\n",
    "            ce_acc_vals.append(acc)\n",
    "            if i % 20 == 0:\n",
    "                print('ZSL Validation Epoch-{:<3d} {:3d}/{:3d} batches \\t'\n",
    "                      'loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'accu {acc.val:.3f} ({acc.avg:.3f})\\t'.format(\n",
    "                       epoch, i , len(val_loader), loss=losses, acc=acces))\n",
    "                print('Vis Reconstruction Loss {:.4f}\\t'\n",
    "                      'Att Reconstruction Loss {:.4f}\\t'\n",
    "                      'MMD Loss {:.4f}\\t'\n",
    "                      'Supervised Binary Prediction Loss {:.4f}'.format(\n",
    "                       vis_recons_loss.item(), att_recons_loss.item(), loss_mmd.item(), pred_loss.item()))\n",
    "                \n",
    "    return losses.avg, acces.avg, scores\n",
    "\n",
    "def validate(train_loader, epoch, margin):\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    ce_loss_vals = []\n",
    "    ce_acc_vals = []\n",
    "    scores = []\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        # (inputs, target) = next(iter(train_loader))\n",
    "        emb = inputs.to(device)\n",
    "        scores.append(emb)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsl_loss, zsl_acc, test_zs = zsl_validate(val_loader, visae, attae, 0)\n",
    "test_seen = np.load('/ssd_scratch/cvit/pranay.gupta/ntu_results/shift_10_r/gtest_out.npy')\n",
    "# validate(val_out_loader, 0, 0.3)\n",
    "# zsl_loss, zsl_acc, seen_zs = zsl_validate(zsl_loader, visae, attae, 0)\n",
    "# val_loss, val_acc, unseen_train = validate(zsl_loader, visae, attae, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tars = []\n",
    "for i, (_, target) in enumerate(val_loader):\n",
    "    tars += list(target.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = []\n",
    "for i in tars:\n",
    "    if i in unseen_inds:\n",
    "        test_y.append(0)\n",
    "    else:\n",
    "        test_y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zs = np.array([j.cpu().detach().numpy() for i in test_zs for j in i])\n",
    "# test_seen = np.array([j.cpu().detach().numpy() for i in test_seen for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seen.shape\n",
    "# test_zs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_scale(seen_features, T):\n",
    "    return np.array([np.exp(i)/np.sum(np.exp(i)) for i in (seen_features + 1e-12)/T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test_zs = np.array([np.exp(i)/np.sum(np.exp(i)) for i in test_zs])\n",
    "prob_test_seen = temp_scale(test_seen, 4)\n",
    "main_prob_test_seen = np.array([np.exp(i)/np.sum(np.exp(i)) for i in test_seen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test_zs = np.sort(prob_test_zs, 1)[:,::-1][:,:10]\n",
    "feat_test_seen = np.sort(prob_test_seen, 1)[:,::-1][:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_test_x = np.concatenate([feat_test_zs, feat_test_seen], 1)\n",
    "gating_test_y = test_y\n",
    "# gating_train_x = np.concatenate([np.concatenate([feat_unseen_zs[train_unseen_inds, :], feat_unseen_train[train_unseen_inds, :]], 1), np.concatenate([feat_seen_zs[train_seen_inds, :], feat_seen_train[train_seen_inds, :]], 1)], 0)\n",
    "# gating_train_y = [0]*len(train_unseen_inds) + [1]*len(train_seen_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('/ssd_scratch/cvit/pranay.gupta/language_modelling/revise_shift_10_r/gating_model_t4_thresh_0.77.pkl', 'rb') as f:\n",
    "    gating_model = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_gate = gating_model.predict_proba(gating_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = 1 - prob_gate[:, 0]>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pred_test==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_val = gating_model.predict(gating_val_x)\n",
    "np.sum(pred_test == test_y)/len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prob_gate\n",
    "b = np.zeros(prob_gate.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gate_seen = prob_gate[:, 1]\n",
    "prob_y_given_seen = main_prob_test_seen + (1/120)*np.repeat((1 - p_gate_seen)[:, np.newaxis], 120, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gate_unseen = prob_gate[:, 0]\n",
    "prob_y_given_unseen = prob_test_zs + (1/10)*np.repeat((1 - p_gate_unseen)[:, np.newaxis], 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_seen = prob_y_given_seen*np.repeat(p_gate_seen[:, np.newaxis], 120, 1)\n",
    "prob_unseen = prob_y_given_unseen*np.repeat(p_gate_unseen[:, np.newaxis], 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_seen[:,unseen_inds] = prob_unseen\n",
    "final_prob = prob_seen\n",
    "final_pred = np.argmax(final_prob, -1)\n",
    "\n",
    "seen_count = 0\n",
    "seen_hit = 0\n",
    "unseen_count = 0\n",
    "unseen_hit = 0\n",
    "gating_seen_hit = 0\n",
    "gating_unseen_hit = 0\n",
    "for i, gt in enumerate(tars):\n",
    "    if gt in seen_inds:\n",
    "        if prob_gate[i, 0] < prob_gate[i, 1]:\n",
    "            gating_seen_hit += 1\n",
    "        seen_count += 1\n",
    "        if final_pred[i] == gt:\n",
    "            seen_hit += 1\n",
    "    else:\n",
    "        if prob_gate[i, 0] > prob_gate[i, 1]:\n",
    "            gating_unseen_hit += 1\n",
    "        unseen_count += 1\n",
    "        if final_pred[i] == gt:\n",
    "            unseen_hit += 1\n",
    "\n",
    "seen_acc = seen_hit/seen_count\n",
    "unseen_acc = unseen_hit/unseen_count\n",
    "h_mean = 2*seen_acc*unseen_acc/(seen_acc + unseen_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_seen_acc = gating_seen_hit/seen_count\n",
    "gating_seen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_unseen_acc = gating_unseen_hit/unseen_count\n",
    "gating_unseen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "\n",
    "# soft gating\n",
    "# for i in range(len(prob_seen)):\n",
    "#     if np.max(prob_seen[i, :]) > np.max(prob_unseen[i, :]):\n",
    "#         pred = seen_inds[np.argmax(prob_seen[i, :])]\n",
    "#     else:\n",
    "#         pred = unseen_inds[np.argmax(prob_unseen[i, :])]\n",
    "#     final_preds.append(pred)\n",
    "\n",
    "# hard gating\n",
    "# final_preds = seen_inds[np.argmax(prob_test_seen, -1)]*pred_test + unseen_inds[np.argmax(prob_test_zs, -1)]*(1-pred_test)\n",
    "seen_count = 0\n",
    "tot_seen = 0\n",
    "unseen_count = 0\n",
    "tot_unseen = 0\n",
    "count = 0\n",
    "for i in range(len(prob_seen)):\n",
    "    if pred_test[i] == 1:\n",
    "        pred = np.argmax(main_prob_test_seen[i, :])\n",
    "    else:\n",
    "        pred = unseen_inds[np.argmax(prob_test_zs[i, :])]\n",
    "    \n",
    "    if tars[i] in seen_inds:\n",
    "        tot_seen += 1\n",
    "        if pred == tars[i]:\n",
    "            seen_count += 1\n",
    "    else:\n",
    "        if pred_test[i] == 0:\n",
    "            count+=1\n",
    "        tot_unseen += 1\n",
    "        if pred == tars[i]:\n",
    "            unseen_count += 1\n",
    "#     final_preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_acc = seen_count/tot_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_acc = unseen_count/tot_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(final_preds) == np.array(tars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mean = 2*seen_acc*unseen_acc/(seen_acc + unseen_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(pred_test == 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
