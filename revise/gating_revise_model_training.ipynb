{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Loaded Revise Model\n",
      "Train on 42665 samples, validate on 4821 samples\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import os.path as osp\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision.models as models\n",
    "from resnext_specialist import VA\n",
    "from data_cnn60 import NTUDataLoaders, AverageMeter, make_dir, get_cases, get_num_classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from ReViSE import VisAE, AttAE, contractive_loss, MMDLoss, sup_bin_pred_loss, multi_class_hinge_loss, triplet_loss\n",
    "\n",
    "parser = argparse.ArgumentParser(description='View adaptive')\n",
    "parser.add_argument('--ss', type=int, help=\"No of unseen classes\")\n",
    "parser.add_argument('--st', type=str, help=\"Type of split\")\n",
    "parser.add_argument('--dataset', type=str, help=\"dataset path\")\n",
    "parser.add_argument('--wdir', type=str, help=\"directory to save weights path\")\n",
    "parser.add_argument('--le', type=str, help=\"language embedding model\")\n",
    "parser.add_argument('--ve', type=str, help=\"visual embedding model\")\n",
    "parser.add_argument('--phase', type=str, help=\"train or val\")\n",
    "parser.add_argument('--gpu', type=str, help=\"gpu device number\")\n",
    "parser.add_argument('--ntu', type=int, help=\"no of classes\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "gpu = '0'\n",
    "ss = 10\n",
    "st = 'r'\n",
    "dataset_path = 'ntu_results/shift_val_10_r'\n",
    "# wdir = args.wdir\n",
    "le = 'bert'\n",
    "ve = 'shift'\n",
    "phase = 'val'\n",
    "num_classes = 120\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "\n",
    "seed = 5\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "zvisae_checkpoint = '/ssd_scratch/cvit/pranay.gupta/language_modelling/revise_shift_val_10_r//bert/gvisae_best.pth.tar'\n",
    "zattae_checkpoint = '/ssd_scratch/cvit/pranay.gupta/language_modelling/revise_shift_val_10_r/bert/gattae_best.pth.tar'\n",
    "criterion2 = nn.MSELoss().to(device)\n",
    "att_input_size = 1024\n",
    "att_intermediate_size = 512\n",
    "att_hidden_size = 100\n",
    "attae = VisAE(att_input_size, att_intermediate_size, att_hidden_size).to(device)\n",
    "attae.load_state_dict(torch.load(zattae_checkpoint)['revise_state_dict'], strict=False)\n",
    "attae_optimizer = optim.Adam(attae.parameters(),lr=1e-4, weight_decay = 0.001)\n",
    "attae_scheduler = ReduceLROnPlateau(attae_optimizer, mode='max', factor=0.1, patience=15, cooldown=3, verbose=True)\n",
    "\n",
    "vis_input_size = 256\n",
    "vis_intermediate_size = 512\n",
    "vis_hidden_size = 100\n",
    "visae = AttAE(vis_input_size, vis_hidden_size).to(device)\n",
    "visae.load_state_dict(torch.load(zvisae_checkpoint)['revise_state_dict'], strict=False)\n",
    "visae_optimizer = optim.Adam(visae.parameters(), lr=1e-4)\n",
    "visae_scheduler = ReduceLROnPlateau(visae_optimizer, mode='max', factor=0.1, patience=15, cooldown=3, verbose=True)\n",
    "print(\"Loaded Revise Model\")\n",
    "\n",
    "ntu_loaders = NTUDataLoaders(dataset_path, 'max', 1)\n",
    "train_loader = ntu_loaders.get_train_loader(1024, 8)\n",
    "zsl_loader = ntu_loaders.get_val_loader(1024, 8)\n",
    "val_loader = ntu_loaders.get_test_loader(1024, 8)\n",
    "zsl_out_loader = ntu_loaders.get_val_out_loader(1024, 8)\n",
    "val_out_loader = ntu_loaders.get_test_out_loader(1024, 8)\n",
    "train_size = ntu_loaders.get_train_size()\n",
    "zsl_size = ntu_loaders.get_val_size()\n",
    "val_size = ntu_loaders.get_test_size()\n",
    "print('Train on %d samples, validate on %d samples' % (train_size, zsl_size))\n",
    "\n",
    "if phase == 'val':\n",
    "    gzsl_inds = np.load('./label_splits/'+st+'s'+str(num_classes - ss)+'.npy')\n",
    "    unseen_inds = np.load('./label_splits/'+st+'v'+str(ss)+'_0.npy')\n",
    "    seen_inds = np.load('./label_splits/'+st+'s'+str(num_classes - ss - ss)+'_0.npy')\n",
    "else:\n",
    "    gzsl_inds = np.arange(num_classes)\n",
    "    unseen_inds = np.load('./label_splits/'+st+'u'+str(ss)+'.npy')\n",
    "    seen_inds = np.load('./label_splits/'+st+'s'+str(num_classes - ss)+'.npy')\n",
    "\n",
    "labels = np.load('labels.npy')\n",
    "unseen_labels = labels[unseen_inds]\n",
    "seen_labels = labels[seen_inds]\n",
    "\n",
    "s2v_labels = torch.from_numpy(np.load(le + '_labels.npy')[:num_classes,:]).view([num_classes, att_input_size])\n",
    "s2v_labels = s2v_labels/torch.norm(s2v_labels, dim = 1).view([num_classes, 1]).repeat([1, att_input_size])\n",
    "\n",
    "unseen_s2v_labels = s2v_labels[unseen_inds, :]\n",
    "seen_s2v_labels = s2v_labels[seen_inds, :]\n",
    "\n",
    "\n",
    "def accuracy(class_embedding, vis_trans_out, target, inds):\n",
    "    inds = torch.from_numpy(inds).to(device)\n",
    "    temp_vis = vis_trans_out.unsqueeze(1).expand(vis_trans_out.shape[0], class_embedding.shape[0], vis_trans_out.shape[1])\n",
    "    temp_cemb = class_embedding.unsqueeze(0).expand(vis_trans_out.shape[0], class_embedding.shape[0], vis_trans_out.shape[1])\n",
    "    preds = torch.argmax(torch.sum(temp_vis*temp_cemb, axis=2), -1)\n",
    "    acc = torch.sum(inds[preds] == target).item()/(preds.shape[0])\n",
    "    # print(torch.sum(inds[preds] == target).item())\n",
    "    return acc, torch.sum(temp_vis*temp_cemb, axis=2)\n",
    "\n",
    "def ce_accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "    return correct.mul_(100.0 / batch_size)\n",
    "\n",
    "def get_text_data(target, s2v_labels):\n",
    "    return s2v_labels[target].view(target.shape[0], 1024)\n",
    "\n",
    "\n",
    "def get_w2v_data(target_nouns, w2v_model, nouns):\n",
    "    \n",
    "    srt_inp = torch.zeros([target_nouns.shape[0], 1, target_nouns.shape[1]]).float()\n",
    "    noun_inp = target_nouns.view(target_nouns.shape[0], 1, target_nouns.shape[1]).float()\n",
    "#     verb_inp = torch.view(target_nouns.shape[0], 1, target_nouns.shape[1])\n",
    "    inp = torch.cat([srt_inp, noun_inp], 1)\n",
    "    return inp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zsl_validate(val_loader, visae, attae, epoch):\n",
    "    with torch.no_grad():\n",
    "        losses = AverageMeter()\n",
    "        acces = AverageMeter()\n",
    "        ce_loss_vals = []\n",
    "        ce_acc_vals = []\n",
    "        # trunk.eval()\n",
    "        visae.eval()\n",
    "        attae.eval()\n",
    "        scores = []\n",
    "        class_embeddings = attae(unseen_s2v_labels.to(device).float())[2]\n",
    "        # unseen_class_embeddings = unseen_class_embeddings/torch.norm(unseen_class_embeddings, dim=1).view([unseen_class_embeddings.size(0), 1]).repeat([1, unseen_class_embeddings.shape[1]])\n",
    "        for i, (emb, target) in enumerate(val_loader):\n",
    "            emb = emb.to(device)\n",
    "            # maxmin = maxmin.to(device)\n",
    "            # vis_emb, output = trunk(emb, maxmin)\n",
    "            # vis_emb = emb/torch.norm(emb, dim = 1).view([emb.size(0), 1]).repeat([1, emb.shape[1]])\n",
    "            vis_emb = torch.log(1 + emb)\n",
    "        \n",
    "            vis_hidden, vis_out, vis_trans_out = visae(vis_emb)\n",
    "            vis_recons_loss = criterion2(vis_out, vis_emb)\n",
    "            \n",
    "            att_emb = get_text_data(target, s2v_labels.float()).to(device)\n",
    "            att_hidden, att_out, att_trans_out = attae(att_emb)\n",
    "            att_recons_loss = criterion2(att_out, att_emb)\n",
    "            \n",
    "            # mmd loss\n",
    "            loss_mmd = MMDLoss(vis_hidden, att_hidden).to(device)\n",
    "            \n",
    "            \n",
    "            # supervised binary prediction loss\n",
    "            pred_loss = multi_class_hinge_loss(vis_trans_out, att_trans_out, target, class_embeddings)\n",
    "            # pred_loss = sup_bin_pred_loss(vis_trans_out, att_trans_out)\n",
    "            # vis_trans_out = vis_trans_out/torch.norm(vis_trans_out, dim = 0).view([1, vis_trans_out.size(1)]).repeat([vis_trans_out.shape[0], 1])\n",
    "            # att_trans_out = att_trans_out/torch.norm(att_trans_out, dim = 0).view([1, att_trans_out.size(1)]).repeat([att_trans_out.shape[0], 1])\n",
    "            # vis_trans_out = vis_trans_out/torch.norm(vis_trans_out, dim = 1).view([vis_trans_out.size(0), 1]).repeat([1, vis_trans_out.shape[1]])\n",
    "            # att_trans_out = att_trans_out/torch.norm(att_trans_out, dim = 1).view([att_trans_out.size(0), 1]).repeat([1, att_trans_out.shape[1]])\n",
    "            # sup_bin_pred_loss = (-1/vis_trans_out.shape[0]) * torch.sum(vis_trans_out*att_trans_out)\n",
    "\n",
    "            loss = pred_loss + vis_recons_loss + att_recons_loss + loss_mmd\n",
    "            acc, score = accuracy(class_embeddings, vis_trans_out, target.to(device), unseen_inds)\n",
    "            losses.update(loss.item(), emb.size(0))\n",
    "            acces.update(acc, emb.size(0))\n",
    "            scores.append(score)\n",
    "            ce_loss_vals.append(loss.cpu().detach().numpy())\n",
    "            ce_acc_vals.append(acc)\n",
    "            if i % 20 == 0:\n",
    "                print('ZSL Validation Epoch-{:<3d} {:3d}/{:3d} batches \\t'\n",
    "                      'loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'accu {acc.val:.3f} ({acc.avg:.3f})\\t'.format(\n",
    "                       epoch, i , len(val_loader), loss=losses, acc=acces))\n",
    "                print('Vis Reconstruction Loss {:.4f}\\t'\n",
    "                      'Att Reconstruction Loss {:.4f}\\t'\n",
    "                      'MMD Loss {:.4f}\\t'\n",
    "                      'Supervised Binary Prediction Loss {:.4f}'.format(\n",
    "                       vis_recons_loss.item(), att_recons_loss.item(), loss_mmd.item(), pred_loss.item()))\n",
    "                \n",
    "    return losses.avg, acces.avg, scores\n",
    "\n",
    "def validate(train_loader, epoch, margin):\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    ce_loss_vals = []\n",
    "    ce_acc_vals = []\n",
    "    scores = []\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        # (inputs, target) = next(iter(train_loader))\n",
    "        emb = inputs.to(device)\n",
    "        scores.append(emb)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZSL Validation Epoch-0     0/  5 batches \tloss 1.7550 (1.7550)\taccu 0.470 (0.470)\t\n",
      "Vis Reconstruction Loss 0.0097\tAtt Reconstruction Loss 0.0009\tMMD Loss 0.2176\tSupervised Binary Prediction Loss 1.5268\n",
      "ZSL Validation Epoch-0     0/  4 batches \tloss 0.1533 (0.1533)\taccu 0.000 (0.000)\t\n",
      "Vis Reconstruction Loss 0.0098\tAtt Reconstruction Loss 0.0008\tMMD Loss 0.0157\tSupervised Binary Prediction Loss 0.1270\n"
     ]
    }
   ],
   "source": [
    "zsl_loss, zsl_acc, unseen_zs = zsl_validate(zsl_loader, visae, attae, 0)\n",
    "seen_train = validate(val_out_loader, 0, 0.3)\n",
    "zsl_loss, zsl_acc, seen_zs = zsl_validate(val_loader, visae, attae, 0)\n",
    "unseen_train = validate(zsl_out_loader, 0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_zs = np.array([j.cpu().detach().numpy() for i in unseen_zs for j in i])\n",
    "unseen_train = np.array([j.cpu().detach().numpy() for i in unseen_train for j in i])\n",
    "seen_zs = np.array([j.cpu().detach().numpy() for i in seen_zs for j in i])\n",
    "seen_train = np.array([j.cpu().detach().numpy() for i in seen_train for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_train.shape\n",
    "seen_zs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# model = LogisticRegression(random_state=0, C=1, solver='lbfgs', n_jobs=-1,\n",
    "#                                  multi_class='multinomial', verbose=1, max_iter=5000,\n",
    "#                                  ).fit(gating_train_x[train_inds, :], np.array(gating_train_y)[train_inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_scale(seen_features, T):\n",
    "    return np.array([np.exp(i)/np.sum(np.exp(i)) for i in (seen_features + 1e-12)/T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zsl_loss, zsl_acc, unseen_zs = zsl_validate(zsl_loader, visae, attae, 0)\n",
    "# val_loss, val_acc, seen_train = validate(val_loader, visae, attae, 0)\n",
    "# zsl_loss, zsl_acc, seen_zs = zsl_validate(val_loader, visae, attae, 0)\n",
    "# val_loss, val_acc, unseen_train = validate(zsl_loader, visae, attae, 0)\n",
    "\n",
    "# unseen_zs = np.array([j for i in unseen_zs for j in i])\n",
    "# unseen_train = np.array([j for i in unseen_train for j in i])\n",
    "# seen_zs = np.array([j for i in seen_zs for j in i])\n",
    "# seen_train = np.array([j for i in seen_train for j in i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "4\n",
      "0.7771428571428571\n",
      "thresh 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "for f in [10]:\n",
    "    print(f)\n",
    "    for t in [4]:\n",
    "        print(t)\n",
    "        fin_val_acc = 0\n",
    "        fin_train_acc = 0\n",
    "        for run in range(1):\n",
    "            prob_unseen_zs = np.array([np.exp(i)/np.sum(np.exp(i)) for i in unseen_zs])\n",
    "            prob_unseen_train = temp_scale(unseen_train, t)\n",
    "        #     np.array([np.exp(i)/np.sum(np.exp(i)) for i in unseen_train])\n",
    "            prob_seen_zs = np.array([np.exp(i)/np.sum(np.exp(i)) for i in seen_zs])\n",
    "            prob_seen_train = temp_scale(seen_train, t)\n",
    "        #     np.array([np.exp(i)/np.sum(np.exp(i)) for i in seen_train])\n",
    "\n",
    "            feat_unseen_zs = np.sort(prob_unseen_zs, 1)[:,::-1][:,:f]\n",
    "            feat_unseen_train = np.sort(prob_unseen_train, 1)[:,::-1][:,:f]\n",
    "            feat_seen_zs = np.sort(prob_seen_zs, 1)[:,::-1][:,:f]\n",
    "            feat_seen_train = np.sort(prob_seen_train, 1)[:,::-1][:,:f]\n",
    "\n",
    "            val_unseen_inds = np.random.choice(np.arange(feat_unseen_zs.shape[0]), 300, replace=False)\n",
    "            val_seen_inds = np.random.choice(np.arange(feat_seen_zs.shape[0]), 400, replace=False)\n",
    "            train_unseen_inds = np.array(list(set(list(np.arange(feat_unseen_zs.shape[0]))) - set(list(val_unseen_inds))))\n",
    "            train_seen_inds = np.array(list(set(list(np.arange(feat_seen_zs.shape[0]))) - set(list(val_seen_inds))))\n",
    "\n",
    "            gating_train_x = np.concatenate([np.concatenate([feat_unseen_zs[train_unseen_inds, :], feat_unseen_train[train_unseen_inds, :]], 1), np.concatenate([feat_seen_zs[train_seen_inds, :], feat_seen_train[train_seen_inds, :]], 1)], 0)\n",
    "            gating_train_y = [0]*len(train_unseen_inds) + [1]*len(train_seen_inds)\n",
    "            gating_val_x = np.concatenate([np.concatenate([feat_unseen_zs[val_unseen_inds, :], feat_unseen_train[val_unseen_inds, :]], 1), np.concatenate([feat_seen_zs[val_seen_inds, :], feat_seen_train[val_seen_inds, :]], 1)], 0)\n",
    "            gating_val_y = [0]*len(val_unseen_inds) + [1]*len(val_seen_inds)\n",
    "\n",
    "            train_inds = np.arange(gating_train_x.shape[0])\n",
    "            np.random.shuffle(train_inds)\n",
    "        #     val_inds = np.arange(gating_val_x.shape[0])\n",
    "        #     np.random.shuffle(val_inds)\n",
    "            model = LogisticRegression(random_state=0, C=1, solver='lbfgs', n_jobs=-1,\n",
    "                                         multi_class='ovr', verbose=1, max_iter=5000,\n",
    "                                         ).fit(gating_train_x[train_inds, :], np.array(gating_train_y)[train_inds])\n",
    "#             prob = model.predict(gating_val_x)\n",
    "            prob = model.predict_proba(gating_val_x)\n",
    "            best = 0\n",
    "            bestT = 0\n",
    "            for t in range(25, 75, 1):\n",
    "                y = prob[:, 0] > t/100\n",
    "                acc = np.sum((1 - y) == gating_val_y)/len(gating_val_y)\n",
    "#                 print(acc)\n",
    "                if acc > best:\n",
    "                    best = acc\n",
    "                    bestT = t/100\n",
    "#             val_acc = np.sum(pred_val == gating_val_y)/len(gating_val_y)\n",
    "            fin_val_acc += best\n",
    "#             pred_train = model.predict_proba(gating_train_x)\n",
    "#             train_acc = np.sum(pred_train == gating_train_y)/len(gating_train_y)\n",
    "#             fin_train_acc += train_acc\n",
    "        print(fin_val_acc/1)\n",
    "        print('thresh', bestT)\n",
    "#         print(fin_train_acc/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('/ssd_scratch/cvit/pranay.gupta/language_modelling/revise_shift_10_r/gating_model_t4_thresh_0.77.pkl', 'wb') as f:\n",
    "    pkl.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_val == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 158,  676, 1386, ..., 1988, 2661,  563])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39060137, 0.19405556, 0.19021037, 0.1321618 , 0.0929709 ,\n",
       "       0.00757515, 0.00528609, 0.00459759, 0.00454435, 0.00446126],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating_train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating_train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4087105 , 0.24862064, 0.17654862, 0.14646363, 0.01965655,\n",
       "       0.00477781, 0.0046028 , 0.00454625, 0.00451198, 0.0044876 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating_train_x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
